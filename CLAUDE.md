# Cortex Lattice MVP - Technical Context

**Version:** 1.0  
**Date:** January 26, 2026  
**Purpose:** AI Safety Learning Platform - Teaching DSA patterns through AI research paper implementations

---

## Project Vision

Cortex Lattice teaches professional problem-solving patterns through interactive coding challenges. This MVP focuses on **AI Safety and Alignment** - teaching the data structures and algorithms needed to implement frontier AI research papers.

### The Core Insight

Every AI safety paper requires 5-10 core algorithmic patterns. Instead of just reading papers, students learn by solving DSA problems that map directly to the code they'll write when implementing:
- Transformers (Attention is All You Need)
- RLHF (InstructGPT) 
- Constitutional AI
- Mechanistic Interpretability
- And 11 more frontier AI safety papers

### What Makes This Different

**Traditional approach:**
- Read paper â†’ Don't understand the algorithms â†’ Struggle with implementation

**Cortex Lattice approach:**
- Solve algorithmic problem â†’ Understand the pattern â†’ See exactly where it's used in the paper â†’ Implement confidently

**Example:**
Before reading Flash Attention paper, solve "Two Pointers - Attention Head Selector" problem. Learn the pattern. THEN read Section 3.2 and recognize: "Oh, this is that two-pointers pattern I just learned!"

---

## Technical Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (Next.js)                   â”‚
â”‚  - Monaco Editor (web) / CodeMirror (mobile)            â”‚
â”‚  - Bottom sheet hint system (iOS Now Playing style)     â”‚
â”‚  - Categorized guidance (5 categories)                  â”‚
â”‚  - Mobile-first responsive design                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ POST /api/execute
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   API Layer (Next.js)                   â”‚
â”‚  - Authentication (future)                              â”‚
â”‚  - Job queue management                                 â”‚
â”‚  - Results processing                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ Docker exec
                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Docker Container (Python)                  â”‚
â”‚  - Python 3.11 + PyTorch (CPU)                          â”‚
â”‚  - Isolated execution environment                       â”‚
â”‚  - 10-second timeout, 512MB memory                      â”‚
â”‚  - Test runner with pass/fail results                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## File Structure

### Project Root
```
cortex-lattice-mvp/
â”œâ”€â”€ README.md
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ frontend/                    # Next.js application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ layout.tsx
â”‚   â”‚   â”œâ”€â”€ page.tsx            # Landing page
â”‚   â”‚   â””â”€â”€ problems/
â”‚   â”‚       â””â”€â”€ [id]/
â”‚   â”‚           â””â”€â”€ page.tsx    # Problem solving interface
â”‚   â”‚
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ CodeEditor.tsx      # Monaco/CodeMirror wrapper
â”‚   â”‚   â”œâ”€â”€ BottomSheet.tsx     # iOS-style hint drawer
â”‚   â”‚   â”œâ”€â”€ HintSystem.tsx      # Categorized hints
â”‚   â”‚   â””â”€â”€ TestResults.tsx     # Pass/fail display
â”‚   â”‚
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ api.ts              # API client
â”‚       â””â”€â”€ types.ts            # TypeScript types
â”‚
â”œâ”€â”€ api/                         # API routes
â”‚   â””â”€â”€ execute/
â”‚       â””â”€â”€ route.ts            # Code execution endpoint
â”‚
â”œâ”€â”€ executor/                    # Docker execution environment
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ run_tests.py            # Test runner
â”‚   â””â”€â”€ requirements.txt
â”‚
â””â”€â”€ problems/                    # Problem content (YAML files)
    â”œâ”€â”€ prerequisites/
    â”‚   â”œâ”€â”€ attention-is-all-you-need/
    â”‚   â”‚   â”œâ”€â”€ two-pointers-attention-head-selector/
    â”‚   â”‚   â”‚   â”œâ”€â”€ problem.yaml
    â”‚   â”‚   â”‚   â”œâ”€â”€ solution.py
    â”‚   â”‚   â”‚   â””â”€â”€ guidance.yaml
    â”‚   â”‚   â””â”€â”€ dynamic-programming-positional-encoding/
    â”‚   â”‚       â”œâ”€â”€ problem.yaml
    â”‚   â”‚       â”œâ”€â”€ solution.py
    â”‚   â”‚       â””â”€â”€ guidance.yaml
    â”‚   â”‚
    â”‚   â””â”€â”€ ppo/
    â”‚       â”œâ”€â”€ sliding-window-experience-buffer/
    â”‚       â”‚   â”œâ”€â”€ problem.yaml
    â”‚       â”‚   â”œâ”€â”€ solution.py
    â”‚       â”‚   â””â”€â”€ guidance.yaml
    â”‚       â””â”€â”€ monotonic-stack-trust-region/
    â”‚           â”œâ”€â”€ problem.yaml
    â”‚           â”œâ”€â”€ solution.py
    â”‚           â””â”€â”€ guidance.yaml
    â”‚
    â”œâ”€â”€ foundations/
    â”‚   â”œâ”€â”€ instructgpt-rlhf/
    â”‚   â””â”€â”€ constitutional-ai/
    â”‚
    â”œâ”€â”€ going-deeper/
    â”‚   â”œâ”€â”€ reward-hacking/
    â”‚   â””â”€â”€ adversarial-prompts/
    â”‚
    â”œâ”€â”€ advanced-safety/
    â”‚   â”œâ”€â”€ multi-objective-rlhf/
    â”‚   â””â”€â”€ safety-testing/
    â”‚
    â”œâ”€â”€ interpretability/
    â”‚   â”œâ”€â”€ activation-steering/
    â”‚   â”œâ”€â”€ transformer-circuits/
    â”‚   â””â”€â”€ neural-probes/
    â”‚
    â”œâ”€â”€ systems/
    â”‚   â”œâ”€â”€ kv-cache/
    â”‚   â””â”€â”€ distributed-training/
    â”‚
    â””â”€â”€ integration/
        â””â”€â”€ end-to-end-safety/
```

---

## The 3-File Teaching Framework

Each problem consists of 3 YAML files:

### 1. problem.yaml (Required)
Standard problem definition - statement, examples, test cases, constraints

### 2. solution.py (Required)
Reference implementation in Python with comments

### 3. guidance.yaml (Required - MVP Innovation)
Categorized hint system with 5 categories:

```yaml
hints:
  # Standard algorithmic guidance
  key_concepts: [...]          # Pattern fundamentals
  common_mistakes: [...]       # Implementation pitfalls
  
  # AI Safety specific (NEW - your secret sauce)
  project_context: [...]       # Where this appears in paper implementations
  paper_reference: [...]       # Direct citations to papers
  
  # Last resort
  solution_approach: [...]     # Step-by-step solution
```

---

## Complete Problem Mapping (28 Problems)

### Theme 1: Prerequisites (4 problems)

#### Paper 1: Attention is All You Need â†’ Mini-GPT Implementation

**Problem 1.1: Two Pointers + Heap - Attention Head Selector**
- **DSA Pattern:** Two Pointers + Min Heap
- **Paper Context:** Section 3.2 - Multi-Head Attention
- **Implementation:** `src/attention.py` - Selective Q-K pair computation
- **Real Usage:** Flash Attention optimization, sparse attention in GPT-4

**Problem 1.2: Dynamic Programming - Positional Encoding Optimization**
- **DSA Pattern:** Dynamic Programming (optimization)
- **Paper Context:** Section 3.5 - Positional Encoding
- **Implementation:** `src/embeddings.py` - Wavelength selection for sinusoidal encodings
- **Real Usage:** RoPE (Rotary Positional Embeddings) in Llama

#### Paper 2: Proximal Policy Optimization â†’ PPO Implementation

**Problem 2.1: Sliding Window - Experience Buffer Sampling**
- **DSA Pattern:** Sliding Window + Weighted Average
- **Paper Context:** Section 3 - Generalized Advantage Estimation (GAE)
- **Implementation:** `src/buffer.py` - Trajectory processing with GAE(Î»)
- **Real Usage:** InstructGPT training, ChatGPT RLHF pipeline

**Problem 2.2: Monotonic Stack - Trust Region Enforcement**
- **DSA Pattern:** Monotonic Stack
- **Paper Context:** Section 3.1 - Clipped Surrogate Objective
- **Implementation:** `src/ppo.py` - Finding valid policy update ranges
- **Real Usage:** Trust region without second-order optimization

---

### Theme 2: Foundations (4 problems)

#### Paper 3: InstructGPT â†’ RLHF Implementation

**Problem 3.1: Priority Queue + Hash Map - Reward Model Training**
- **DSA Pattern:** Max Heap + Hash Map
- **Paper Context:** Section 3.2 - Reward Model Training
- **Implementation:** `src/reward_model.py` - Preference pair selection
- **Real Usage:** Anthropic's Constitutional AI, OpenAI's InstructGPT

**Problem 3.2: Graph (Topological Sort) - Training Pipeline Dependencies**
- **DSA Pattern:** Directed Acyclic Graph + Topological Sort
- **Paper Context:** Section 3 - Three-stage training pipeline
- **Implementation:** `src/pipeline.py` - SFT â†’ RM â†’ PPO dependency management
- **Real Usage:** Complex training pipelines in production LLMs

#### Paper 4: Constitutional AI â†’ Self-Improvement Systems

**Problem 4.1: DFS/BFS - Self-Critique Chain Detection**
- **DSA Pattern:** Depth-First Search + Cycle Detection
- **Paper Context:** Section 2.1 - Critique â†’ Revision chains
- **Implementation:** `src/constitution.py` - Principle violation traversal
- **Real Usage:** Claude's Constitutional AI, self-refinement loops

**Problem 4.2: Two Pointers - Harmlessness-Helpfulness Tradeoff**
- **DSA Pattern:** Two Pointers on sorted arrays
- **Paper Context:** Section 3.3 - Balancing objectives
- **Implementation:** `src/objectives.py` - Pareto frontier search
- **Real Usage:** Multi-objective optimization in AI safety

---

### Theme 3: Going Deeper (4 problems)

#### Paper 5: Specification Gaming Research â†’ Reward Hacking Detection

**Problem 5.1: Interval Scheduling - Anomaly Detection Windows**
- **DSA Pattern:** Interval Scheduling + Greedy
- **Paper Context:** Section 2 - Temporal violation patterns
- **Implementation:** `src/detector.py` - Non-overlapping anomaly windows
- **Real Usage:** OpenAI's learned reward model monitoring

**Problem 5.2: Binary Search - Reward Threshold Tuning**
- **DSA Pattern:** Binary Search on answer space
- **Paper Context:** Section 4 - Optimal detection thresholds
- **Implementation:** `src/thresholds.py` - Precision-recall optimization
- **Real Usage:** Adversarial robustness in production systems

#### Paper 6: Red Teaming Research â†’ Adversarial Prompt Detection

**Problem 6.1: Trie + DFS - Jailbreak Template Matching**
- **DSA Pattern:** Trie + Depth-First Search
- **Paper Context:** Section 3.1 - Pattern-based detection
- **Implementation:** `src/patterns.py` - Efficient template matching
- **Real Usage:** ChatGPT's moderation API, Claude's safety filters

**Problem 6.2: KMP Algorithm - Prompt Injection Detection**
- **DSA Pattern:** Knuth-Morris-Pratt string matching
- **Paper Context:** Section 3.2 - Substring injection attacks
- **Implementation:** `src/injection_detector.py` - Linear-time pattern search
- **Real Usage:** Production LLM safety layers

---

### Theme 4: Advanced Safety (4 problems)

#### Paper 7: Multi-Objective RLHF â†’ Balancing Multiple Goals

**Problem 7.1: Merge Sort + Two Pointers - Pareto Optimal Solutions**
- **DSA Pattern:** Merge Sort + Two Pointers
- **Paper Context:** Section 2 - Multi-objective optimization
- **Implementation:** `src/pareto.py` - Non-dominated solution identification
- **Real Usage:** Balancing helpfulness, harmlessness, honesty

**Problem 7.2: Convex Hull - Objective Space Boundary**
- **DSA Pattern:** Graham Scan (Convex Hull)
- **Paper Context:** Section 3 - Feasible region analysis
- **Implementation:** `src/objectives.py` - Frontier computation
- **Real Usage:** Claude's multi-objective preference model

#### Paper 8: Safety Testing Framework â†’ Systematic Evaluation

**Problem 8.1: Union-Find - Test Property Equivalence**
- **DSA Pattern:** Disjoint Set Union (Union-Find)
- **Paper Context:** Section 2.1 - Property clustering
- **Implementation:** `src/test_suite.py` - Equivalence class detection
- **Real Usage:** Anthropic's safety evaluations

**Problem 8.2: Reservoir Sampling - Unbiased Evaluation Sampling**
- **DSA Pattern:** Reservoir Sampling
- **Paper Context:** Section 3.2 - Statistical testing methodology
- **Implementation:** `src/sampling.py` - Representative test selection
- **Real Usage:** Large-scale model evaluation pipelines

---

### Theme 5: Interpretability (6 problems)

#### Paper 9: Activation Steering â†’ Controlling Model Behavior

**Problem 9.1: Binary Search - Optimal Steering Direction**
- **DSA Pattern:** Binary Search + Linear Algebra
- **Paper Context:** Section 2 - Activation space navigation
- **Implementation:** `src/steering.py` - Direction magnitude optimization
- **Real Usage:** Anthropic's activation engineering research

**Problem 9.2: PCA/SVD - Principal Component Projection**
- **DSA Pattern:** Singular Value Decomposition (math/numpy)
- **Paper Context:** Section 3 - Dimensionality reduction
- **Implementation:** `src/projections.py` - Activation space compression
- **Real Usage:** Understanding high-dimensional representations

#### Paper 10: Transformer Circuits â†’ Mechanistic Interpretability

**Problem 10.1: Graph Algorithms (SCC) - Circuit Detection**
- **DSA Pattern:** Strongly Connected Components (Tarjan's)
- **Paper Context:** Section 2.1 - Attention head circuits
- **Implementation:** `src/circuits.py` - Computational graph analysis
- **Implementation:** `src/circuits.py` - Computational graph analysis
- **Real Usage:** Anthropic's interpretability research, identifying induction heads

**Problem 10.2: Union-Find - Feature Attribution**
- **DSA Pattern:** Disjoint Set Union
- **Paper Context:** Section 3.2 - Connected neuron groups
- **Implementation:** `src/attribution.py` - Component clustering
- **Real Usage:** Understanding distributed representations

#### Paper 11: Neural Network Probes â†’ Representation Analysis

**Problem 11.1: Linear Algebra - Maximum Margin Classifier**
- **DSA Pattern:** Linear Algebra (optimization)
- **Paper Context:** Section 2 - Linear probing methodology
- **Implementation:** `src/probes.py` - SVM-style classifier training
- **Real Usage:** Anthropic's research on model representations

**Problem 11.2: Cross-Validation - K-Fold Splitting Strategy**
- **DSA Pattern:** Array partitioning + rotation
- **Paper Context:** Section 3.1 - Probe evaluation methodology
- **Implementation:** `src/evaluation.py` - Stratified K-fold implementation
- **Real Usage:** Rigorous interpretability research methods

---

### Theme 6: Systems (4 problems)

#### Paper 12: KV Cache Systems â†’ Efficient Inference

**Problem 12.1: LRU Cache - Key-Value Eviction**
- **DSA Pattern:** Hash Map + Doubly Linked List (LRU)
- **Paper Context:** Section 2 - Cache management strategies
- **Implementation:** `src/kv_cache.py` - Memory-efficient attention caching
- **Real Usage:** Production transformer inference (GPT-4, Claude)

**Problem 12.2: Segment Tree - Range-Based Memory Allocation**
- **DSA Pattern:** Segment Tree + Lazy Propagation
- **Paper Context:** Section 3 - Dynamic memory management
- **Implementation:** `src/memory.py` - Efficient batch allocation
- **Real Usage:** vLLM, TGI (Text Generation Inference) systems

#### Paper 13: Distributed Training â†’ Scaling to Multiple GPUs

**Problem 13.1: Consistent Hashing - Load Balancing**
- **DSA Pattern:** Consistent Hashing
- **Paper Context:** Section 2.1 - Data parallel distribution
- **Implementation:** `src/distributed.py` - Even GPU workload distribution
- **Real Usage:** DeepSpeed, Megatron-LM training pipelines

**Problem 13.2: Gossip Protocol - Efficient Gradient Synchronization**
- **DSA Pattern:** Graph algorithms (spanning tree)
- **Paper Context:** Section 3 - All-reduce optimization
- **Implementation:** `src/sync.py` - Bandwidth-efficient gradient averaging
- **Real Usage:** Ring all-reduce in NCCL

---

### Theme 7: Integration (2 problems)

#### Paper 14: End-to-End Safety System â†’ Putting It All Together

**Problem 14.1: Pipeline Design - Multi-Stage Safety Filtering**
- **DSA Pattern:** Pipeline pattern + topological ordering
- **Paper Context:** Integration section - Layered defense
- **Implementation:** `src/safety_pipeline.py` - Moderation â†’ filtering â†’ monitoring
- **Real Usage:** Production LLM safety stacks

**Problem 14.2: Circuit Breaker Pattern - System Failure Detection**
- **DSA Pattern:** State machine + sliding window
- **Paper Context:** Section 4 - Robust deployment
- **Implementation:** `src/monitoring.py` - Failure detection and graceful degradation
- **Real Usage:** Production inference systems

---

## guidance.yaml Structure (5 Categories)

Each problem includes a `guidance.yaml` file with 5 hint categories:

```yaml
title: "Two Pointers - Attention Head Selector"
pattern: "Two Pointers + Min Heap"

# Link to implementation project
project_mapping:
  primary: "mini-gpt-from-scratch"
  paper: "Attention is All You Need"
  paper_section: "3.2 - Multi-Head Attention"
  file: "src/attention.py"
  function: "compute_selective_attention"

hints:
  # Category 1: Standard DSA concepts
  key_concepts:
    - text: "Use two pointers to traverse sorted query and key arrays"
    - text: "Maintain a min-heap of size k to track top-k pairs"
    - text: "Sort pairs by similarity score: qÂ·k dot product"
    - text: "Time complexity: O(n log k) vs O(nÂ² log k) naive"

  # Category 2: Implementation pitfalls
  common_mistakes:
    - text: "âš ï¸ Don't compute all nÂ² pairs - defeats the purpose"
    - text: "âš ï¸ Min-heap stores smallest k, but you want largest k scores"
    - text: "âš ï¸ Handle edge case: k > total possible pairs"

  # Category 3: Where this appears in YOUR implementations (NEW)
  project_context:
    - text: |
        ğŸ¤– Mini-GPT Attention Layer
        
        When you implement your transformer, full attention is O(nÂ²):
        ```
        attention_scores = query @ key.T  # Computes ALL pairs
        ```
        
        This pattern lets you select only top-k pairs before computing
        attention, reducing to O(nk). This is how Flash Attention achieves
        3-5x speedup on long sequences.
        
        You'll implement this in `src/attention.py`:
        ```
        top_pairs = find_top_k_qk_pairs(q, k, k=32)
        sparse_attn = compute_attention(q, k, v, pairs=top_pairs)
        ```
        
    - text: |
        ğŸ¤– Real Numbers
        
        Mini-GPT with 512-token sequences:
        - Full attention: 512 Ã— 512 = 262,144 Q-K pairs
        - Top-32 attention: 512 Ã— 32 = 16,384 pairs
        - 16x fewer computations per head!
        
        With 12 attention heads: saves ~3M operations per forward pass

  # Category 4: Paper citations (NEW)
  paper_reference:
    - text: |
        ğŸ“„ Flash Attention: Fast and Memory-Efficient Exact Attention
        Dao et al., 2022
        
        Section 3.2: "Block-Sparse Attention Selection"
        
        "We maintain the top-k query-key pairs using a priority queue
        during block-wise computation, reducing attention score
        calculations from O(nÂ²) to O(nk)."
        
        Algorithm 2 (page 6) shows the implementation.
        
        [Read paper â†’] [Code reference â†’]

  # Category 5: Step-by-step solution (last resort)
  solution_approach:
    steps:
      - "Sort queries and keys by magnitude (preprocessing)"
      - "Initialize min-heap of size k"
      - "For each query q_i:"
      - "  Use two pointers to find keys with highest qÂ·k scores"
      - "  Insert (score, q_idx, k_idx) into heap"
      - "  If heap.size > k: pop minimum"
      - "Return heap contents as top-k pairs"

complexity:
  time: "O(n log k)"
  space: "O(k)"
```

---

## Mobile-First UX Design

### Bottom Sheet Interaction (iOS Now Playing Style)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â† Two Pointers - Attention Selector â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                      â”‚
â”‚    CODE EDITOR (FULL SCREEN)        â”‚
â”‚                                      â”‚
â”‚  def find_top_k_pairs(               â”‚
â”‚      queries: List[float],           â”‚
â”‚      keys: List[float],              â”‚
â”‚      k: int                          â”‚
â”‚  ) -> List[Tuple[int, int]]:        â”‚
â”‚      # Your code here                â”‚
â”‚      pass                            â”‚
â”‚                                      â”‚
â”‚                                      â”‚
â”‚                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Tests: 2/5 âœ“  [â–¶ Run Tests]        â”‚
â”‚  Need help? [Swipe up â–²]            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**User swipes up â†’ Bottom sheet appears:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    CODE EDITOR (PARTIAL VIEW)        â”‚
â”‚  def find_top_k_pairs(               â”‚
â”œâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â”¤ â† Drag handle
â”‚  Choose a hint category:             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€º ğŸ’¡ Key Concepts (4)          â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€º âš ï¸  Common Mistakes (3)      â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€º ğŸ¤– Project Context (2)       â”‚  â”‚
â”‚  â”‚   Mini-GPT attention layer     â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€º ğŸ“„ Paper Reference (1)       â”‚  â”‚
â”‚  â”‚   Flash Attention Â§3.2         â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€º ğŸ¯ Solution Approach (1)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**User taps "ğŸ¤– Project Context":**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ë… ğŸ¤– Project Context (0/2 shown)    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                                â”‚  â”‚
â”‚  â”‚ No hints revealed yet          â”‚  â”‚
â”‚  â”‚                                â”‚  â”‚
â”‚  â”‚ [Show First Hint]              â”‚  â”‚
â”‚  â”‚                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                      â”‚
â”‚  â€º ğŸ’¡ Key Concepts (4)               â”‚
â”‚  â€º âš ï¸  Common Mistakes (3)           â”‚
â”‚  â€º ğŸ“„ Paper Reference (1)            â”‚
â”‚  â€º ğŸ¯ Solution Approach (1)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**User reveals first hint:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ë… ğŸ¤– Project Context (1/2)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ¤– Mini-GPT Attention Layer    â”‚  â”‚
â”‚  â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚  â”‚
â”‚  â”‚                                â”‚  â”‚
â”‚  â”‚ When you implement your        â”‚  â”‚
â”‚  â”‚ transformer, full attention    â”‚  â”‚
â”‚  â”‚ computes ALL query-key pairs   â”‚  â”‚
â”‚  â”‚ (O(nÂ²) operations).            â”‚  â”‚
â”‚  â”‚                                â”‚  â”‚
â”‚  â”‚ This pattern teaches you to    â”‚  â”‚
â”‚  â”‚ select only top-k pairs,       â”‚  â”‚
â”‚  â”‚ reducing to O(nk).             â”‚  â”‚
â”‚  â”‚                                â”‚  â”‚
â”‚  â”‚ Flash Attention uses this for  â”‚  â”‚
â”‚  â”‚ 3-5x speedup!                  â”‚  â”‚
â”‚  â”‚                                â”‚  â”‚
â”‚  â”‚ [Show Next Hint]               â”‚  â”‚
â”‚  â”‚                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â€º Other categories...               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Development Roadmap

### Week 1: MVP Core (5 problems)

**Goal:** Functional prototype with mobile-first UI

**Problems to create:**
1. Two Pointers - Attention Head Selector (Mini-GPT)
2. Sliding Window - Experience Buffer (PPO)
3. Dynamic Programming - Positional Encoding (Mini-GPT)
4. Monotonic Stack - Trust Region (PPO)
5. Priority Queue - Reward Model Pairs (RLHF)

**Features:**
- âœ… Next.js frontend with responsive design
- âœ… Monaco Editor (web) / CodeMirror (mobile)
- âœ… Bottom sheet hint system (iOS style)
- âœ… 5-category guidance system
- âœ… Local Docker execution (Python + PyTorch)
- âœ… Basic pass/fail test results
- âœ… Works great on mobile

**Time estimate:** 40-50 hours
- 5 problems Ã— 3 hours each = 15 hours
- Frontend development = 15 hours
- Docker setup = 5 hours
- Testing & polish = 10 hours

---

### Month 1: Expand to 14 Problems (One Per Paper)

**Goal:** Cover all 14 papers with one problem each

**Additional problems:**
- Constitutional AI (DFS)
- Reward Hacking (Interval Scheduling)
- Adversarial Prompts (Trie)
- Multi-Objective RLHF (Merge Sort)
- Safety Testing (Union-Find)
- Activation Steering (Binary Search)
- Transformer Circuits (SCC)
- Neural Probes (Linear Algebra)
- KV Cache (LRU)
- Distributed Training (Consistent Hashing)
- End-to-End Safety (Pipeline)

**New features:**
- âœ… User accounts (simple email/password)
- âœ… Progress tracking (which problems solved)
- âœ… Problem filtering by paper/pattern
- âœ… Basic analytics (time to solve, hints used)

**Time estimate:** 30 hours
- 9 new problems Ã— 3 hours = 27 hours
- Auth & progress tracking = 10 hours
- UI improvements = 8 hours

---

### Month 3: Complete Collection (28 Problems)

**Goal:** Two problems per paper, enhanced teaching

**Additional problems:**
- Second problem for each paper (14 more problems)
- Add `invariants.yaml` to 5 showcase problems
- Add `mistakes.yaml` to 5 showcase problems
- Richer visualizations for top problems

**New features:**
- âœ… Pattern collection tracking
- âœ… "Learn this pattern" recommendations
- âœ… Progress visualization (pattern mastery)
- âœ… Share solutions (public/private toggle)

**Time estimate:** 50 hours
- 14 new problems Ã— 3 hours = 42 hours
- 5 problems enhanced (invariants + mistakes) Ã— 2.5 hours = 12.5 hours
- New features = 15 hours

---

### Month 6: Production Ready

**Goal:** Deploy to cloud, add community features

**Infrastructure:**
- âœ… Deploy to Vercel (frontend)
- âœ… AWS ECS for Docker execution (backend)
- âœ… PostgreSQL for user data
- âœ… Redis for job queue
- âœ… S3 for code storage

**Features:**
- âœ… Social features (follow users, share solutions)
- âœ… Leaderboards (per problem, per pattern)
- âœ… Discussion threads per problem
- âœ… Code review feature
- âœ… Email notifications

---

## Tech Stack

### Frontend
- **Framework:** Next.js 14 (App Router)
- **Language:** TypeScript
- **Styling:** Tailwind CSS
- **Code Editor:** Monaco (web), CodeMirror 6 (mobile)
- **State Management:** React Context + hooks
- **HTTP Client:** fetch (native)

### Backend
- **API:** Next.js API routes
- **Language:** TypeScript (Node.js)
- **Database:** PostgreSQL (future)
- **Cache:** Redis (future)
- **Job Queue:** BullMQ (future)

### Execution Environment
- **Container:** Docker
- **Base Image:** python:3.11-slim
- **Runtime:** Python 3.11
- **ML Framework:** PyTorch 2.0 (CPU)
- **Testing:** pytest
- **Timeout:** 10 seconds
- **Memory Limit:** 512MB

### DevOps
- **Version Control:** Git
- **Hosting:** Vercel (frontend), AWS ECS (executor)
- **CI/CD:** GitHub Actions
- **Monitoring:** Vercel Analytics (MVP)

---

## Key Implementation Details

### Code Execution Flow

```typescript
// frontend/lib/api.ts
export async function executeCode(problemId: string, code: string) {
  const response = await fetch('/api/execute', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ problemId, code })
  });
  
  return await response.json();
}
```

```typescript
// api/execute/route.ts
import { exec } from 'child_process';
import { promisify } from 'util';

const execAsync = promisify(exec);

export async function POST(request: Request) {
  const { problemId, code } = await request.json();
  
  // Write code to temp file
  const tempFile = `/tmp/${Date.now()}.py`;
  await fs.writeFile(tempFile, code);
  
  // Execute in Docker
  const { stdout, stderr } = await execAsync(
    `docker run --rm ` +
    `-v ${tempFile}:/code/solution.py ` +
    `-v ./problems/${problemId}:/code/problem ` +
    `--memory=512m ` +
    `--cpus=1 ` +
    `--network=none ` +
    `cortex-executor python run_tests.py`
  );
  
  // Parse results
  const results = JSON.parse(stdout);
  
  return Response.json(results);
}
```

```python
# executor/run_tests.py
import sys
import yaml
from pathlib import Path

def run_tests(problem_dir: Path):
    # Load problem definition
    with open(problem_dir / 'problem.yaml') as f:
        problem = yaml.safe_load(f)
    
    # Import user solution
    sys.path.insert(0, '/code')
    from solution import *
    
    # Run test cases
    results = []
    for i, test in enumerate(problem['test_cases']):
        try:
            # Execute function
            fn = eval(problem['function_name'])
            output = fn(**test['input'])
            
            # Check result
            passed = output == test['expected']
            results.append({
                'test': i + 1,
                'passed': passed,
                'output': output,
                'expected': test['expected']
            })
        except Exception as e:
            results.append({
                'test': i + 1,
                'passed': False,
                'error': str(e)
            })
    
    # Return results as JSON
    print(json.dumps({
        'total': len(results),
        'passed': sum(r['passed'] for r in results),
        'results': results
    }))

if __name__ == '__main__':
    run_tests(Path('/code/problem'))
```

---

## Future Enhancements (Post-MVP)

### Phase 2: Enhanced Teaching (Month 2-3)
- âœ… Add `invariants.yaml` to problems
- âœ… Add `mistakes.yaml` for better feedback
- âœ… Detect common errors, provide specific guidance
- âœ… Show "This violates the X invariant" messages

### Phase 3: Interactive Learning (Month 4-6)
- âœ… Add `pause-points.yaml` for interactive debugging
- âœ… Step-through code execution
- âœ… "Predict next step" challenges
- âœ… Visual execution traces

### Phase 4: Community (Month 6+)
- âœ… User-generated problems
- âœ… Problem reviews and ratings
- âœ… Study groups
- âœ… Collaborative solving mode

### Phase 5: Advanced Features (Year 1+)
- âœ… AI tutor (GPT-4/Claude integration)
- âœ… Code review suggestions
- âœ… Personalized learning paths
- âœ… Certificate program

---

## Success Metrics

### Week 1 MVP
- âœ… 5 problems created with full guidance
- âœ… Mobile-responsive UI works smoothly
- âœ… Code execution returns results in <5 seconds
- âœ… 5 beta testers can solve at least 1 problem

### Month 1
- âœ… 14 problems (one per paper)
- âœ… 50+ test users
- âœ… 70% completion rate on attempted problems
- âœ… Average 3-4 hints used per solve

### Month 3
- âœ… 28 problems (complete collection)
- âœ… 500+ registered users
- âœ… 5,000+ problem attempts
- âœ… Users report learning the pattern transfer concept

### Month 6
- âœ… 1,000+ active users
- âœ… 80% solve rate after using hints
- âœ… Users successfully implement papers after solving problems
- âœ… First paying customers ($20/month tier)

---

## Getting Started (Developer Setup)

```bash
# Clone repository
git clone <repo-url>
cd cortex-lattice-mvp

# Install dependencies
npm install

# Set up Docker
docker build -t cortex-executor ./executor

# Create first problem content
mkdir -p problems/prerequisites/attention-is-all-you-need/two-pointers-attention-head-selector

# Run development server
npm run dev

# Open browser
open http://localhost:3000
```

---

## Environment Variables

```bash
# .env.local
NEXT_PUBLIC_API_URL=http://localhost:3000
DOCKER_IMAGE=cortex-executor
EXECUTION_TIMEOUT=10000
MAX_MEMORY=512m
```

---

## Contact & Resources

**Project Owner:** Jacob  
**Primary Goal:** Learn AI safety by building, create portfolio for FAANG/trading firms  
**Timeline:** Week 1 MVP â†’ Month 6 launch  
**Business Model:** Worker-owned cooperative, $997/year individual pricing

**Key Papers:**
- Attention is All You Need (Vaswani et al., 2017)
- Proximal Policy Optimization (Schulman et al., 2017)
- Training language models to follow instructions with human feedback (Ouyang et al., 2022)
- Constitutional AI (Anthropic, 2022)
- Flash Attention (Dao et al., 2022)
- And 9 more...

---

**This document provides complete context for any developer (including Claude Code) to understand and contribute to Cortex Lattice MVP.**
